//! Streaming Events Demo
//!
//! This example demonstrates the new streaming token events feature.
//! It shows how broadcasters can opt-in to receive real-time streaming tokens
//! as they are generated by the LLM, enabling features like:
//! - Real-time SSE (Server-Sent Events) streaming
//! - Live progress indicators
//! - Token-by-token WebSocket updates
//!
//! The demo includes:
//! - StreamingBroadcaster: Receives and displays each token as it arrives
//! - ConsoleBroadcaster: Only receives high-level events (backward compatible)
//! - Comparison between streaming and non-streaming modes

use agents_core::agent::AgentHandle;
use agents_core::events::{AgentEvent, EventBroadcaster};
use agents_core::messaging::AgentMessage;
use agents_core::state::AgentStateSnapshot;
use agents_sdk::{ConfigurableAgentBuilder, OpenAiChatModel, OpenAiConfig};
use async_trait::async_trait;
use futures::StreamExt;
use std::sync::Arc;
use tokio::sync::Mutex;

/// A broadcaster that supports streaming token events
/// This simulates an SSE or WebSocket broadcaster that sends tokens in real-time
struct StreamingBroadcaster {
    id: String,
    accumulated_text: Arc<Mutex<String>>,
}

impl StreamingBroadcaster {
    fn new() -> Self {
        Self {
            id: "streaming".to_string(),
            accumulated_text: Arc::new(Mutex::new(String::new())),
        }
    }

    async fn get_accumulated_text(&self) -> String {
        self.accumulated_text.lock().await.clone()
    }

    async fn reset(&self) {
        self.accumulated_text.lock().await.clear();
    }
}

#[async_trait]
impl EventBroadcaster for StreamingBroadcaster {
    fn id(&self) -> &str {
        &self.id
    }

    fn supports_streaming(&self) -> bool {
        true // This broadcaster wants streaming token events
    }

    async fn broadcast(&self, event: &AgentEvent) -> anyhow::Result<()> {
        match event {
            AgentEvent::StreamingToken(e) => {
                // Accumulate and display tokens in real-time
                let mut text = self.accumulated_text.lock().await;
                text.push_str(&e.token);

                // Print the token immediately (like SSE would send it)
                print!("{}", e.token);
                std::io::Write::flush(&mut std::io::stdout()).ok();
            }
            AgentEvent::AgentCompleted(e) => {
                println!("\n\nâœ… Streaming Complete!");
                println!("   Agent: {}", e.agent_name);
                println!("   Duration: {}ms", e.duration_ms);
            }
            _ => {}
        }
        Ok(())
    }
}

/// A traditional broadcaster that only receives high-level events
/// This demonstrates backward compatibility - existing broadcasters work unchanged
struct ConsoleBroadcaster {
    id: String,
}

impl ConsoleBroadcaster {
    fn new() -> Self {
        Self {
            id: "console".to_string(),
        }
    }
}

#[async_trait]
impl EventBroadcaster for ConsoleBroadcaster {
    fn id(&self) -> &str {
        &self.id
    }

    // supports_streaming() defaults to false, so no streaming events

    async fn broadcast(&self, event: &AgentEvent) -> anyhow::Result<()> {
        match event {
            AgentEvent::AgentStarted(e) => {
                println!("\nğŸ“¡ [Console] Agent Started: {}", e.agent_name);
                println!("   Message: {}", e.message_preview);
            }
            AgentEvent::AgentCompleted(e) => {
                println!("\nğŸ“¡ [Console] Agent Completed: {}", e.agent_name);
                println!("   Duration: {}ms", e.duration_ms);
                println!("   Response: {}", e.response_preview);
            }
            AgentEvent::StreamingToken(_) => {
                // This should never be called because supports_streaming() = false
                println!("\nâš ï¸ [Console] Received streaming token (this shouldn't happen!)");
            }
            _ => {}
        }
        Ok(())
    }
}

#[tokio::main]
async fn main() -> anyhow::Result<()> {
    // Initialize logging
    tracing_subscriber::fmt()
        .with_max_level(tracing::Level::INFO)
        .init();

    // Load environment variables
    dotenvy::dotenv().ok();
    let api_key = std::env::var("OPENAI_API_KEY").expect("OPENAI_API_KEY must be set in .env file");

    println!("\nğŸ¯ Streaming Events Demo");
    println!("========================\n");
    println!("This demo shows how broadcasters can receive real-time streaming tokens.");
    println!("We'll demonstrate:");
    println!("  1. StreamingBroadcaster - receives token-by-token updates");
    println!("  2. ConsoleBroadcaster - only receives high-level events");
    println!();

    // Create broadcasters
    let streaming_broadcaster = Arc::new(StreamingBroadcaster::new());
    let console_broadcaster = Arc::new(ConsoleBroadcaster::new());

    // Create agent with both broadcasters
    let agent = ConfigurableAgentBuilder::new(
        "You are a helpful assistant. Provide clear and concise answers.",
    )
    .with_model(Arc::new(OpenAiChatModel::new(OpenAiConfig::new(
        api_key,
        "gpt-4o-mini",
    ))?))
    .with_event_broadcasters(vec![
        streaming_broadcaster.clone() as Arc<dyn EventBroadcaster>,
        console_broadcaster.clone() as Arc<dyn EventBroadcaster>,
    ])
    .build()?;

    println!("âœ… Agent created with two broadcasters:");
    println!("   - StreamingBroadcaster (supports_streaming = true)");
    println!("   - ConsoleBroadcaster (supports_streaming = false)");
    println!();

    // Test 1: Streaming Mode
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ“ TEST 1: Streaming Mode (handle_message_stream)");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    println!("Question: Explain what Rust is in 2-3 sentences.\n");
    println!("ğŸ”„ Streaming response (token-by-token):\n");

    streaming_broadcaster.reset().await;

    let message = AgentMessage {
        role: agents_core::messaging::MessageRole::User,
        content: agents_core::messaging::MessageContent::Text(
            "Explain what Rust is in 2-3 sentences.".to_string(),
        ),
        metadata: None,
    };

    let mut stream = agent
        .handle_message_stream(message.clone(), Arc::new(AgentStateSnapshot::default()))
        .await?;

    // Consume the stream (tokens are being printed by StreamingBroadcaster)
    while let Some(chunk) = stream.next().await {
        match chunk {
            Ok(_) => {
                // Chunks are being broadcast to StreamingBroadcaster
            }
            Err(e) => {
                eprintln!("\nâŒ Stream error: {}", e);
                break;
            }
        }
    }

    let streamed_text = streaming_broadcaster.get_accumulated_text().await;
    println!("\n\nğŸ“Š Streaming Statistics:");
    println!("   Total characters streamed: {}", streamed_text.len());
    println!("   Tokens received via StreamingBroadcaster: âœ…");
    println!();

    // Wait a moment to see the console broadcaster output
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;

    // Test 2: Non-Streaming Mode (for comparison)
    println!("\nâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ“ TEST 2: Non-Streaming Mode (handle_message)");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");
    println!("Question: What is the capital of France?\n");
    println!("â³ Waiting for complete response...\n");

    let response = agent
        .handle_message(
            "What is the capital of France?",
            Arc::new(AgentStateSnapshot::default()),
        )
        .await?;

    if let agents_core::messaging::MessageContent::Text(text) = &response.content {
        println!("ğŸ’¬ Complete Response: {}\n", text);
    }

    println!("ğŸ“Š Non-Streaming Statistics:");
    println!("   Response received as: single complete message");
    println!("   No streaming tokens emitted");
    println!();

    // Wait for any pending events
    tokio::time::sleep(tokio::time::Duration::from_millis(500)).await;

    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”");
    println!("ğŸ‰ Demo Complete!");
    println!("â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\n");

    println!("âœ¨ Key Takeaways:");
    println!("   1. StreamingBroadcaster with supports_streaming() = true");
    println!("      â†’ Received real-time token events via AgentEvent::StreamingToken");
    println!();
    println!("   2. ConsoleBroadcaster with supports_streaming() = false (default)");
    println!("      â†’ Only received high-level events (AgentStarted, AgentCompleted)");
    println!("      â†’ Never received streaming tokens");
    println!();
    println!("   3. Backward Compatibility:");
    println!("      â†’ Existing broadcasters work unchanged");
    println!("      â†’ Opt-in to streaming via supports_streaming()");
    println!();
    println!("   4. Use Cases:");
    println!("      â†’ SSE (Server-Sent Events) for web apps");
    println!("      â†’ WebSocket real-time updates");
    println!("      â†’ Progress indicators");
    println!("      â†’ Live chat interfaces");
    println!();

    Ok(())
}
